{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ViT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlhW43aqDL3N"
      },
      "source": [
        "<center><h1>VISION TRANSFORMER (ViT)</h1></center>\n",
        "Because there is a presentation associated with this code, I will not be extensively annotating it. If you have any questions, please do not hesitate to contact me. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPNbvWEanwv-"
      },
      "source": [
        "\n",
        "#########################################\n",
        "######   INSTALLATIONS FOR COLAB   ######\n",
        "#########################################\n",
        "\n",
        "!pip install torch_lr_finder\n",
        "!pip install timm\n",
        "\n",
        "###########################\n",
        "######   LIBRARIES   ######\n",
        "###########################\n",
        "\n",
        "# ------ STANDARD ------ #\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import statistics \n",
        "from tqdm.notebook import tqdm  \n",
        "import random\n",
        "%matplotlib inline\n",
        "\n",
        "# ------ GOOGLE COLAB ------ #\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ------ TORCH MODULES ------ #\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import ToTensor, Compose, Normalize, Resize\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import random_split\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch_lr_finder import LRFinder\n",
        "\n",
        "# ------ TIMM ------ #\n",
        "import timm\n",
        "\n",
        "# ------ SKLEARN MODULES ------ #\n",
        "import scipy.io\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ------  IMAGE DISPLAY ------ #\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import seaborn as sns\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "\n",
        "# ----- CUDA ------ #\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeR0cKQjDfXf"
      },
      "source": [
        "<h2>READING IN THE DATA AND CREATING THE DATA LOADERS</h2>\n",
        "All rather straight forward here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y4BHLZK47ht"
      },
      "source": [
        "# ----- PATH -----\n",
        "root_dir = \"/content/drive/My Drive/\"\n",
        "training_directory = root_dir + 'ML_FinalProject/data/train'\n",
        "validation_directory = root_dir + 'ML_FinalProject/data/validation'\n",
        "test_directory = root_dir + 'ML_FinalProject/data/test'\n",
        "\n",
        "# ----- TRANSFORMS / STANDARDIZATION -----\n",
        "\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std = [0.229, 0.224, 0.225]\n",
        "    \n",
        "standard_transform = Compose([\n",
        "                        Resize((224, 224)),\n",
        "                        ToTensor(), \n",
        "                        Normalize(mean = imagenet_mean, \n",
        "                                  std = imagenet_std)\n",
        "                    ])\n",
        "\n",
        "test_transform = Compose([\n",
        "                        Resize((224, 224)),\n",
        "                        ToTensor()\n",
        "                    ])\n",
        "\n",
        "# ----- BUILD IMAGE FOLDERS -----\n",
        "\n",
        "training_data = ImageFolder(training_directory, \n",
        "                            transform = standard_transform)\n",
        "\n",
        "validation_data = ImageFolder(validation_directory, \n",
        "                              transform = standard_transform)\n",
        "\n",
        "test_data = ImageFolder(test_directory, \n",
        "                              transform = test_transform)\n",
        "\n",
        "# ----- DATA LOADERS -----\n",
        "\n",
        "# Batch size \n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(training_data, \n",
        "                          batch_size, \n",
        "                          shuffle=True, \n",
        "                          num_workers=4, \n",
        "                          pin_memory=True)\n",
        "\n",
        "val_loader = DataLoader(validation_data, \n",
        "                        batch_size, \n",
        "                        num_workers=4, \n",
        "                        pin_memory=True)\n",
        "\n",
        "test_loader = DataLoader(test_data, \n",
        "                        1, \n",
        "                        num_workers=4, \n",
        "                        pin_memory=True)\n",
        "\n",
        "# ----- NAMING THEM FOR MODEL TRAINING -----\n",
        "\n",
        "image_datasets = {}\n",
        "image_datasets['train'] = training_data\n",
        "image_datasets['val'] = validation_data\n",
        "\n",
        "dataloaders = {}\n",
        "dataloaders['train'] = train_loader\n",
        "dataloaders['val'] = val_loader\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbSBIIm8G_WW"
      },
      "source": [
        "<H2>LOADING THE PRE-TRAINED ViT MODEL</h2>\n",
        "Using the Pytorch implementation through the Timm library. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G-W3WWr6Om1"
      },
      "source": [
        "# ------ DEFINING THE MODEL ----- # \n",
        "\n",
        "'''\n",
        "Vision Transformer\n",
        "    paper: https://arxiv.org/abs/2010.11929\n",
        "    model last updated: May 5th, 2021\n",
        "    \n",
        "    notes: \n",
        "      Parameters are frozen. Tests after unfreezing the parameters led to \n",
        "      unfavorable results, even after trials using dynamic learning rates.\n",
        "      Best results from model with unfrozen weights:\n",
        "          Training accuracy: 97%\n",
        "          Validation accracy: 45%\n",
        "'''\n",
        "\n",
        "ViT = timm.create_model('vit_base_patch16_224', pretrained = True)\n",
        "\n",
        "for param in ViT.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "ViT.head = nn.Linear(ViT.head.in_features, 15)\n",
        "ViT = ViT.to(device)\n",
        "ViT.eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45veFYkMHDyS"
      },
      "source": [
        "<h2> SELECTING THE HYPERPARAMETERS</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEOCk_xe6Sex"
      },
      "source": [
        "\n",
        "# ------ PARARMETERS ------ #\n",
        "epochs = 25\n",
        "gamma = 0.1\n",
        "step_size = 5\n",
        "\n",
        "# ----- LOSS FUNCTION AND OPTIMIZER ------ # \n",
        "\n",
        "'''\n",
        "Cross entropy loss was selected because it was the most frequently used in transfer\n",
        "learning in the papers I read. The literature used both Adam and SGD as optimization\n",
        "functions; the original ViT paper stated that Adam performed better across the board\n",
        "on Transfer learning datasets. compared to SGD. However, follow up papers did not mention \n",
        "this finding and primarily use SGD. I tried both optimizers and found that Adam provided\n",
        "a trivial increase over SGD; there was no substantial difference. \n",
        "\n",
        "A learning rate search was conducted to find the best learning rate for the model.\n",
        "'''\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(ViT.parameters(), lr = 1e-7)\n",
        "\n",
        "'''\n",
        "What was the best learning rate? \n",
        "1e-2\n",
        "'''\n",
        "\n",
        "#lr_finder = LRFinder(ViT, optimizer, criterion, device = \"cuda\")\n",
        "#lr_finder.range_test(train_loader, end_lr = 1, num_iter = 50)\n",
        "#lr_finder.plot()\n",
        "\n",
        "# Updating optimizer with new learning rate\n",
        "lr = 1e-2\n",
        "optimizer = optim.SGD(ViT.parameters(), lr = lr)\n",
        "\n",
        "# ----- MODEL SCHEDULER ------ # \n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size = step_size, gamma = gamma)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCDvDqZt2oZv"
      },
      "source": [
        "<h1>TRAINING THE MODEL</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci22C1s-2jl7"
      },
      "source": [
        "\n",
        "best_accuracy = 0\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "\n",
        "    for data, label in tqdm(train_loader):\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        output = ViT(data)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = (output.argmax(dim=1) == label).float().mean()\n",
        "        epoch_accuracy += acc / len(train_loader)\n",
        "        epoch_loss += loss / len(train_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        epoch_val_accuracy = 0\n",
        "        epoch_val_loss = 0\n",
        "        for data, label in val_loader:\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            val_output = ViT(data)\n",
        "            val_loss = criterion(val_output, label)\n",
        "\n",
        "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
        "            epoch_val_accuracy += acc / len(val_loader)\n",
        "            epoch_val_loss += val_loss / len(val_loader)\n",
        "    \n",
        "    if epoch_val_accuracy > best_accuracy:\n",
        "      torch.save(ViT.state_dict(), 'bestViT.pt')\n",
        "      best_accuracy = epoch_val_accuracy\n",
        "\n",
        "    print(\n",
        "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWojWgZA_-Pu"
      },
      "source": [
        "<h2>Testing the Model</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyAp1BpLQVfc",
        "outputId": "c225d9f2-c0c1-4094-f572-1b9aba389b32"
      },
      "source": [
        "# ------ Load in the Best BabyNet ------ #\n",
        "\n",
        "ViT.load_state_dict(torch.load('bestViT.pt'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG4E2d9b_9mm"
      },
      "source": [
        "\n",
        "def predict(model, images):\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        return predicted\n",
        "\n",
        "acc_list = []\n",
        "misclassified_image = []\n",
        "misclassified_label = []\n",
        "y = []\n",
        "y_pred = []\n",
        "\n",
        "acc_list = []\n",
        "for image, label in test_loader:\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "    preds = predict(ViT, image)\n",
        "    y.append(label.item())\n",
        "    y_pred.append(preds.item())\n",
        "    if preds != label:\n",
        "      misclassified_image.append(image)\n",
        "      misclassified_label.append(preds)\n",
        "      test_accuracy = 0\n",
        "    else:\n",
        "      test_accuracy = 1\n",
        "    acc_list.append(test_accuracy)\n",
        "    \n",
        "statistics.mean(acc_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eAmTilmLqMc"
      },
      "source": [
        "<h2>INVESTIGATING AND VISUALIZING THE RESULTS</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZdvTi08ainU"
      },
      "source": [
        "def class_mapper(li):\n",
        "  ''' \n",
        "  A function to replace the numeric Pytorch class identifiers with the associated breed name to aid in visualization clarity. \n",
        "  \n",
        "  Input: \n",
        "    li: List of predicted/true responses encoded as 0 - 15, each of which corresponds to a distinct cat breed\n",
        "  Output: \n",
        "    label_li: List of the predicted/true responses with the code replaced with the name of the breed\n",
        "  ''' \n",
        "    classes = ['Abyssinian', 'Bengal', 'Birman', 'Bombay', 'British Shorthair', 'Egyptian Mau', 'Maine Coon', 'Oriental Shorthair', 'Persian', 'Ragdoll', 'Russian Blue', 'Scottish Fold', 'Siamese', 'Somali', 'Sphynx']\n",
        "    label_li = [classes[i] for i in li]\n",
        "    return label_li"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_hz6YMwLuma"
      },
      "source": [
        "<b>Updating the labels for visualization</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVLGkggvcnoL"
      },
      "source": [
        "misclassified_label = class_mapper(misclassified_label)\n",
        "misclassified_true = class_mapper(misclassified_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LZkqP4OLyLr"
      },
      "source": [
        "<b>Viewing Misclassified Test Observations</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koM6ImFpSfOL"
      },
      "source": [
        "\n",
        "test = [image[0].cpu() for image in misclassified_image]\n",
        "\n",
        "fig = plt.figure(1, figsize=(15, 15))\n",
        "grid = ImageGrid(fig, 111, nrows_ncols=(2, 5), axes_pad=0.05)\n",
        "\n",
        "for i,j in enumerate(random.sample(range(0, 50), 10)):\n",
        "    image = test[j]\n",
        "    label = misclassified_label[j]\n",
        "    true = misclassified_true[j]\n",
        "    ax = grid[i]\n",
        "    ax.imshow(image.permute(1,2,0))\n",
        "    ax.text(10, 210, f\"P: {label} \\nT: {true}\", color='w', backgroundcolor='k')\n",
        "    ax.axis(False)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaL0Ftyrg9xn"
      },
      "source": [
        "\n",
        "y_true = class_mapper(y)\n",
        "y_predictions = class_mapper(y_pred)\n",
        "classes = ['Abyssinian', 'Bengal', 'Birman', 'Bombay', 'British Shorthair', 'Egyptian Mau', 'Maine Coon', 'Oriental Shorthair', \n",
        "           'Persian', 'Ragdoll', 'Russian Blue', 'Scottish Fold', 'Siamese', 'Somali', 'Sphynx']\n",
        "cf_matrix = confusion_matrix(y_true, y_predictions)\n",
        "fig, ax = plt.subplots(figsize=(15,10)) \n",
        "sns.heatmap(cf_matrix, linewidths=1, xticklabels=classes,yticklabels=classes, annot=True, ax=ax, fmt='g')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}